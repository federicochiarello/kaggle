{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-08-01T06:56:56.676522Z","iopub.execute_input":"2022-08-01T06:56:56.67808Z","iopub.status.idle":"2022-08-01T06:56:56.682882Z","shell.execute_reply.started":"2022-08-01T06:56:56.67803Z","shell.execute_reply":"2022-08-01T06:56:56.68189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Introduction\n\nThis month's Tabular Playground Series is a binary classification problem:\n\n> The August 2022 edition of the Tabular Playground Series in an opportunity to help the fictional company Keep It Dry improve its main product Super Soaker. The product is used in factories to absorb spills and leaks.\n> \n> The company has just completed a large testing study for different product prototypes. Can you use this data to build a model that predicts product failures?\n> \n\nLet's first read in the data and take a look at what we are dealing with:","metadata":{}},{"cell_type":"code","source":"sample = pd.read_csv('/kaggle/input/tabular-playground-series-aug-2022/sample_submission.csv')\ntrain = pd.read_csv('/kaggle/input/tabular-playground-series-aug-2022/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-aug-2022/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-08-01T06:56:56.684897Z","iopub.execute_input":"2022-08-01T06:56:56.685439Z","iopub.status.idle":"2022-08-01T06:56:56.892588Z","shell.execute_reply.started":"2022-08-01T06:56:56.685396Z","shell.execute_reply":"2022-08-01T06:56:56.891448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-01T06:56:56.89444Z","iopub.execute_input":"2022-08-01T06:56:56.894877Z","iopub.status.idle":"2022-08-01T06:56:56.923436Z","shell.execute_reply.started":"2022-08-01T06:56:56.894843Z","shell.execute_reply":"2022-08-01T06:56:56.922332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()\n\nNrows,Ncols = train.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-01T06:56:56.925108Z","iopub.execute_input":"2022-08-01T06:56:56.926085Z","iopub.status.idle":"2022-08-01T06:56:56.947455Z","shell.execute_reply.started":"2022-08-01T06:56:56.926035Z","shell.execute_reply":"2022-08-01T06:56:56.946281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The data consists of some information about different products, specicially a product code, `loading`, the type of construction material (`attribute_0` and `attribute_1`) and some unknown numerical data (`attribute_2` and `attribute_3`).","metadata":{}},{"cell_type":"code","source":"\nplt.figure(figsize=(24,6))\nfor i in range(6):\n    plt.subplot(1,6,i+1)\n    train[train.columns[i+1]].hist()\n    _=plt.title(f'Distribution of {train.columns[i+1]}')\n","metadata":{"execution":{"iopub.status.busy":"2022-08-01T06:56:56.949784Z","iopub.execute_input":"2022-08-01T06:56:56.95038Z","iopub.status.idle":"2022-08-01T06:56:57.932016Z","shell.execute_reply.started":"2022-08-01T06:56:56.950345Z","shell.execute_reply":"2022-08-01T06:56:57.930608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The `product_code` feature seems more or less uniformly distributed amongst A, B, C, D, and E. The `loading` feature is a numerical feature with a slight positive skew, but we could possibly get away with assuming this is normally distributed. The `attribute_i` features are categorical variables (possibly ordinal variables), with unbalanced (non-uniform) distributions suggesting that we may need to consider this when splitting the data for cross validation, and is also something to keep in mind when we get to setting up and choosing the model.\n\nThe test set consists of new products as evidenced by the values of the `product_code` feature in the test set (see below). For prediction, we can initially drop the product code from the training and test set, although there might be some hidden information in this feature.","metadata":{}},{"cell_type":"code","source":"test['product_code'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-08-01T06:56:57.93354Z","iopub.execute_input":"2022-08-01T06:56:57.934011Z","iopub.status.idle":"2022-08-01T06:56:57.946139Z","shell.execute_reply.started":"2022-08-01T06:56:57.933966Z","shell.execute_reply":"2022-08-01T06:56:57.944639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Missing data analysis\n\nLet's turn to missing data. I recently discovered the [missingno](https://github.com/ResidentMario/missingno) package which draws missing data figures very easily. It is already installed in the kaggle environment so there is no need to `pip install` this package, just import it.","metadata":{}},{"cell_type":"code","source":"import missingno as msno\n\nmsno.matrix(train.iloc[np.random.choice(range(Nrows), 250)])","metadata":{"execution":{"iopub.status.busy":"2022-08-01T06:56:57.947899Z","iopub.execute_input":"2022-08-01T06:56:57.94827Z","iopub.status.idle":"2022-08-01T06:56:58.574636Z","shell.execute_reply.started":"2022-08-01T06:56:57.948229Z","shell.execute_reply":"2022-08-01T06:56:58.573516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It is clear that missing data needs to be dealt with here. Some of the `loading` features are missing, as well as some of the `measurement_i` variables. Next, we'll print out a list of the number of missing items per feature in both the training set and the test set:","metadata":{}},{"cell_type":"code","source":"train.drop(['failure'],axis=1).isna().sum().to_frame().rename(columns={0:'Training set'}).join(test.isna().sum().rename('Test set'))","metadata":{"execution":{"iopub.status.busy":"2022-08-01T06:56:58.576246Z","iopub.execute_input":"2022-08-01T06:56:58.576565Z","iopub.status.idle":"2022-08-01T06:56:58.605184Z","shell.execute_reply.started":"2022-08-01T06:56:58.576536Z","shell.execute_reply":"2022-08-01T06:56:58.603851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The missingness seems similar between both the training and the test set. The product code and the \"attribute\" features are all completely non-missing. `measurement_i`, for $i \\leq 2$ are all non-missing. `measurement_i` for $i \\geq 3$ have some missing values and have progressively increasing proportion of missingness. This suggests that there are a series of measurements, the results of which determine whether or not later tests are carried out. The probabilities of later measurements being missing doesn't appear to be too strongly related to the missingness of earlier measurements, as inferred from `msno.heatmap` (not shown here), however the dendrogram analysis from msno shows a definite pattern:","metadata":{}},{"cell_type":"code","source":"msno.dendrogram(train)","metadata":{"execution":{"iopub.status.busy":"2022-08-01T06:56:58.606528Z","iopub.execute_input":"2022-08-01T06:56:58.607292Z","iopub.status.idle":"2022-08-01T06:56:59.105456Z","shell.execute_reply.started":"2022-08-01T06:56:58.607254Z","shell.execute_reply":"2022-08-01T06:56:59.104334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The interpretation of this figure (from the[ missingno readme file](https://github.com/ResidentMario/missingno#readme) is that variables that are more likely to be missing together have join closer to zero on the y-axis. Thus there is a definite relationship between the missingness of `measurement_i` variables as $i$ increases. Missingness might also be related to the value (and not just the presence or absence) of previous measurements. We should probably treat infilling of the measurements carefully and try to understand why measeurements are missing. ","metadata":{}},{"cell_type":"markdown","source":"# Distribution of the measurement variables","metadata":{}},{"cell_type":"markdown","source":"The measurement variables are all nicely normally distributed. It looks like some variables are integers, particularly `measurement_0`, `measurement_1` and `measurement_2`, with the rest continuous variables.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,20))\n_=train[[x for x in train.columns if 'measurement' in x]].hist(ax=plt.gca())","metadata":{"execution":{"iopub.status.busy":"2022-08-01T06:56:59.107318Z","iopub.execute_input":"2022-08-01T06:56:59.107699Z","iopub.status.idle":"2022-08-01T06:57:01.683348Z","shell.execute_reply.started":"2022-08-01T06:56:59.107667Z","shell.execute_reply":"2022-08-01T06:57:01.682206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in [x for x in train.columns if 'measurement' in x]:\n    print(f'Variable {col}: {len(train[col].value_counts())} unique values')\n","metadata":{"execution":{"iopub.status.busy":"2022-08-01T06:57:01.686444Z","iopub.execute_input":"2022-08-01T06:57:01.686844Z","iopub.status.idle":"2022-08-01T06:57:01.719504Z","shell.execute_reply.started":"2022-08-01T06:57:01.686808Z","shell.execute_reply":"2022-08-01T06:57:01.718219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Distribution of target variable (success/failure)","metadata":{}},{"cell_type":"markdown","source":"Probability of failure is around 1/5 based on the distribution of the `failure` features in the test set. As with the unbalanced nature of the `attribute` features, we may need to take this into consideration in later modelling steps, particularly when designing any cross-validation schemes.","metadata":{}},{"cell_type":"code","source":"train['failure'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-08-01T06:57:01.721088Z","iopub.execute_input":"2022-08-01T06:57:01.72146Z","iopub.status.idle":"2022-08-01T06:57:01.729812Z","shell.execute_reply.started":"2022-08-01T06:57:01.721431Z","shell.execute_reply":"2022-08-01T06:57:01.728801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Simple data cleaning pipeline\n\nThe basic steps in data cleaning here are to infill the missing data somehow, and encoding of the categorical variables (`attribute_0` and `attribute_1`). Although we saw that missingness in the measurements is probably related to values and/or missingness in ealier measurements, and possibly other variables. However, for now, let's use a simple imputation method and infill with the median for the measurement variables. We can drop `id` as it contains no predictive information. `product_code` is not useful at this stage either as there are different products in the training and test dataset. ","metadata":{}},{"cell_type":"code","source":"missing_cols = list(train.columns[train.isna().sum()>0])\ncategorical_cols = ['attribute_0', 'attribute_1']\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OrdinalEncoder\npreprocessing = ColumnTransformer([('median_infill', SimpleImputer(strategy='median'), missing_cols),\n                                   ('ordinal_encode', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value = -1), categorical_cols)],\n                                  remainder='passthrough')\n\npreprocessing.fit_transform(train.drop(['id','product_code','failure'], axis=1))\npreprocessing.transform(test.drop(['id','product_code'], axis=1))","metadata":{"execution":{"iopub.status.busy":"2022-08-01T06:57:01.731472Z","iopub.execute_input":"2022-08-01T06:57:01.731845Z","iopub.status.idle":"2022-08-01T06:57:01.8811Z","shell.execute_reply.started":"2022-08-01T06:57:01.731814Z","shell.execute_reply":"2022-08-01T06:57:01.879569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Baseline model - XGBoost regressor\n\nLet's fit a model to the end of the data preprocessing pipeline, and make some predictions as a baseline. I manually tuned a few of the hyper-parameters.\n","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBRegressor\nfrom sklearn.pipeline import Pipeline\nmodelling_pipeline = Pipeline(steps = (['preprocessing', preprocessing],\n                                       ['xgboost', XGBRegressor(n_estimators = 350,\n                                                                objective = 'binary:logistic',\n                                                                eval_metric = 'auc',\n                                                                eta = 0.2,\n                                                                max_depth = 2,\n                                                                gamma = 1.2,\n                                                                random_state = 200)]))","metadata":{"execution":{"iopub.status.busy":"2022-08-01T07:02:37.293938Z","iopub.execute_input":"2022-08-01T07:02:37.29468Z","iopub.status.idle":"2022-08-01T07:02:37.304247Z","shell.execute_reply.started":"2022-08-01T07:02:37.294615Z","shell.execute_reply":"2022-08-01T07:02:37.303053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nFirst, we split the training data into training/test dataset to get an estimate of the evaluation score prior to submitting it to the competition. For now, let's use `train_test_split`, although in future we may want to use a more sophisticated cross-validation scheme to stratify and group feature, as discussed above.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nXtr, Xte, ytr, yte = train_test_split(train.drop(['id','product_code','failure'], axis=1), train['failure'],\n                                      test_size=0.2, random_state = 123)\nfrom sklearn.metrics import roc_auc_score # Evaluation metric\nmodelling_pipeline.fit(Xtr, ytr)\nprint(f'Estimated score: {roc_auc_score(yte, modelling_pipeline.predict(Xte)):0.3f}')","metadata":{"execution":{"iopub.status.busy":"2022-08-01T07:02:38.638986Z","iopub.execute_input":"2022-08-01T07:02:38.640023Z","iopub.status.idle":"2022-08-01T07:02:43.17682Z","shell.execute_reply.started":"2022-08-01T07:02:38.639968Z","shell.execute_reply":"2022-08-01T07:02:43.175833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For submission purposes, use the entire training data set to make predictions:","metadata":{}},{"cell_type":"code","source":"modelling_pipeline.fit(train.drop(['id','product_code','failure'], axis=1), train['failure'])\n\npredictions = modelling_pipeline.predict(test.drop(['id','product_code'], axis=1))\n\nsubmission = pd.DataFrame({'id': test['id'],\n                           'failure': predictions})\n\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-08-01T06:57:10.211178Z","iopub.execute_input":"2022-08-01T06:57:10.212196Z","iopub.status.idle":"2022-08-01T06:57:20.05034Z","shell.execute_reply.started":"2022-08-01T06:57:10.212158Z","shell.execute_reply":"2022-08-01T06:57:20.049478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submit to competition\n\nThanks for reading, comments are welcome.","metadata":{}}]}